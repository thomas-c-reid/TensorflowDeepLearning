{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Installling Dependencies**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "numpy 1.16.1 is needed to work with dataset"
      ],
      "metadata": {
        "id": "B2cYB3EU6_93"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2AA2hyy6e9g"
      },
      "outputs": [],
      "source": [
        "!pip install numpy==1.16.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D"
      ],
      "metadata": {
        "id": "Q2-VeKNS8MxX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Data**"
      ],
      "metadata": {
        "id": "NCn2huzo82UL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = keras.datasets.imdb\n",
        "(train_data, train_labels), (test_data, test_labels) = data.load_data(num_words = 10000)\n",
        "print(test_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_LGUpDu810u",
        "outputId": "e3ae8ed7-f0d3-454b-88b6-5c0eafe5ae30"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n",
            "[1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 7944, 451, 202, 14, 6, 717]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Index Mapping**"
      ],
      "metadata": {
        "id": "AkgwDs9X-3fQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = keras.datasets.imdb.get_word_index()\n",
        "word_index = {k:(v+3) for k, v in word_index.items()}\n",
        "\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhU6KjZC-8XF",
        "outputId": "609d0652-e48b-4247-c4f0-771fa6851ca5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1641221/1641221 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_review(text):\n",
        "  return \" \".join([reverse_word_index.get(i, \"?\") for i in text])"
      ],
      "metadata": {
        "id": "qOvN1jNR_G5C"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode_review(test_data[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7jF3Nk2_WRb",
        "outputId": "7038da7a-3a9a-4d92-c214-4be3d4d3e2f8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<START> please give this one a miss br br <UNK> <UNK> and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite <UNK> so all you madison fans give this a miss\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre-Processing**"
      ],
      "metadata": {
        "id": "GkeEOgYHAa4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data, value=word_index[\"<PAD>\"], padding=\"post\", maxlen=250)\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data, value=word_index[\"<PAD>\"], padding=\"post\", maxlen=250)"
      ],
      "metadata": {
        "id": "Tppj0jJfAdGn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_val = train_data[:10000]\n",
        "x_train = train_data[10000:]\n",
        "\n",
        "y_val = train_labels[:10000]\n",
        "y_train = train_labels[10000:]"
      ],
      "metadata": {
        "id": "Ptlb9XmNZHNw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building The Model**"
      ],
      "metadata": {
        "id": "2CWuLXJ9A9Sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(10000, 16))\n",
        "model.add(keras.layers.GlobalAveragePooling1D())\n",
        "model.add(keras.layers.Dense(16, activation=\"ReLU\"))\n",
        "model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=binary_crossentropy, metrics=[\"accuracy\"])\n",
        "\n",
        "# fitModel = model.fit(x_train, y_train, epochs=40, batch_size=512, validataion_data=(x_val, y_val), verbose=1)\n",
        "fitModel = model.fit(x_train, y_train, epochs=40, batch_size=512, validation_data=(x_val, y_val), verbose=1)\n",
        "\n",
        "results = model.evaluate(test_data, test_labels)\n",
        "\n",
        "print(results)\n",
        "\n",
        "test_review = test_data[0]\n",
        "test_review = np.expand_dims(test_review, axis=0) # Add a batch dimension\n",
        "predict = model.predict(test_review)\n",
        "print(\"Review: \")\n",
        "print(decode_review(test_review[0]))\n",
        "print(\"Prediction: \" +str(predict[0]))\n",
        "print(\"Actual: \" + str(test_labels[0]))\n",
        "print(results)\n",
        "\n",
        "model.save(\"model.h5\")\n",
        "\n",
        "\n",
        "# CODE ABOVE CAN BE WRITTEN AS:\n",
        "# model = Sequential([\n",
        "#     Embedding(10000, 16),\n",
        "#     GlobalAveragePooling1D(),\n",
        "#     Dense(16, activation='relu'),\n",
        "#     Dense(1, activation='sigmoid')\n",
        "# ])\n",
        "\n",
        "# model.compile(loss=binary_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
        "# fitModel = model.fit(x_train, y_train, epochs=40, batch_size=512, validation_data=(x_val, y_val), verbose=1)\n",
        "# results = model.evaluate(test_data, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVyhDItuBN7t",
        "outputId": "58976c61-12ca-4fea-8150-6d208ff9aa95"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_12 (Embedding)    (None, None, 16)          160000    \n",
            "                                                                 \n",
            " global_average_pooling1d_12  (None, 16)               0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 16)                272       \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160,289\n",
            "Trainable params: 160,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/40\n",
            "30/30 [==============================] - 2s 28ms/step - loss: 0.6914 - accuracy: 0.5691 - val_loss: 0.6891 - val_accuracy: 0.5893\n",
            "Epoch 2/40\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.6842 - accuracy: 0.6961 - val_loss: 0.6791 - val_accuracy: 0.7266\n",
            "Epoch 3/40\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.6693 - accuracy: 0.7439 - val_loss: 0.6611 - val_accuracy: 0.7424\n",
            "Epoch 4/40\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.6438 - accuracy: 0.7708 - val_loss: 0.6323 - val_accuracy: 0.7663\n",
            "Epoch 5/40\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.6072 - accuracy: 0.7881 - val_loss: 0.5945 - val_accuracy: 0.7862\n",
            "Epoch 6/40\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.5624 - accuracy: 0.8120 - val_loss: 0.5515 - val_accuracy: 0.8032\n",
            "Epoch 7/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.5140 - accuracy: 0.8319 - val_loss: 0.5070 - val_accuracy: 0.8219\n",
            "Epoch 8/40\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.4660 - accuracy: 0.8505 - val_loss: 0.4662 - val_accuracy: 0.8332\n",
            "Epoch 9/40\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.4223 - accuracy: 0.8646 - val_loss: 0.4311 - val_accuracy: 0.8413\n",
            "Epoch 10/40\n",
            "30/30 [==============================] - 1s 49ms/step - loss: 0.3854 - accuracy: 0.8750 - val_loss: 0.4012 - val_accuracy: 0.8524\n",
            "Epoch 11/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3536 - accuracy: 0.8845 - val_loss: 0.3780 - val_accuracy: 0.8591\n",
            "Epoch 12/40\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.3276 - accuracy: 0.8906 - val_loss: 0.3590 - val_accuracy: 0.8655\n",
            "Epoch 13/40\n",
            "30/30 [==============================] - 2s 85ms/step - loss: 0.3050 - accuracy: 0.8977 - val_loss: 0.3446 - val_accuracy: 0.8670\n",
            "Epoch 14/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2857 - accuracy: 0.9027 - val_loss: 0.3319 - val_accuracy: 0.8724\n",
            "Epoch 15/40\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.2687 - accuracy: 0.9067 - val_loss: 0.3222 - val_accuracy: 0.8745\n",
            "Epoch 16/40\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.2539 - accuracy: 0.9129 - val_loss: 0.3137 - val_accuracy: 0.8790\n",
            "Epoch 17/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2405 - accuracy: 0.9170 - val_loss: 0.3071 - val_accuracy: 0.8803\n",
            "Epoch 18/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2281 - accuracy: 0.9219 - val_loss: 0.3021 - val_accuracy: 0.8810\n",
            "Epoch 19/40\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.2170 - accuracy: 0.9257 - val_loss: 0.2978 - val_accuracy: 0.8821\n",
            "Epoch 20/40\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.2068 - accuracy: 0.9293 - val_loss: 0.2947 - val_accuracy: 0.8818\n",
            "Epoch 21/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1977 - accuracy: 0.9326 - val_loss: 0.2906 - val_accuracy: 0.8845\n",
            "Epoch 22/40\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.1883 - accuracy: 0.9377 - val_loss: 0.2887 - val_accuracy: 0.8840\n",
            "Epoch 23/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1802 - accuracy: 0.9410 - val_loss: 0.2874 - val_accuracy: 0.8846\n",
            "Epoch 24/40\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.1721 - accuracy: 0.9447 - val_loss: 0.2861 - val_accuracy: 0.8847\n",
            "Epoch 25/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1647 - accuracy: 0.9483 - val_loss: 0.2866 - val_accuracy: 0.8848\n",
            "Epoch 26/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1581 - accuracy: 0.9509 - val_loss: 0.2857 - val_accuracy: 0.8861\n",
            "Epoch 27/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1515 - accuracy: 0.9527 - val_loss: 0.2853 - val_accuracy: 0.8868\n",
            "Epoch 28/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.1451 - accuracy: 0.9563 - val_loss: 0.2870 - val_accuracy: 0.8856\n",
            "Epoch 29/40\n",
            "30/30 [==============================] - 1s 33ms/step - loss: 0.1401 - accuracy: 0.9567 - val_loss: 0.2883 - val_accuracy: 0.8862\n",
            "Epoch 30/40\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.1343 - accuracy: 0.9603 - val_loss: 0.2887 - val_accuracy: 0.8858\n",
            "Epoch 31/40\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.1286 - accuracy: 0.9625 - val_loss: 0.2894 - val_accuracy: 0.8858\n",
            "Epoch 32/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1237 - accuracy: 0.9635 - val_loss: 0.2916 - val_accuracy: 0.8864\n",
            "Epoch 33/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1185 - accuracy: 0.9663 - val_loss: 0.2941 - val_accuracy: 0.8861\n",
            "Epoch 34/40\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.1144 - accuracy: 0.9678 - val_loss: 0.2966 - val_accuracy: 0.8853\n",
            "Epoch 35/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1094 - accuracy: 0.9693 - val_loss: 0.2982 - val_accuracy: 0.8854\n",
            "Epoch 36/40\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.1053 - accuracy: 0.9710 - val_loss: 0.3010 - val_accuracy: 0.8850\n",
            "Epoch 37/40\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.1011 - accuracy: 0.9730 - val_loss: 0.3034 - val_accuracy: 0.8849\n",
            "Epoch 38/40\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.0971 - accuracy: 0.9743 - val_loss: 0.3061 - val_accuracy: 0.8834\n",
            "Epoch 39/40\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.0937 - accuracy: 0.9760 - val_loss: 0.3104 - val_accuracy: 0.8818\n",
            "Epoch 40/40\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.0898 - accuracy: 0.9775 - val_loss: 0.3129 - val_accuracy: 0.8825\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.3354 - accuracy: 0.8705\n",
            "[0.335410475730896, 0.8704800009727478]\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "Review: \n",
            "<START> please give this one a miss br br <UNK> <UNK> and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite <UNK> so all you madison fans give this a miss <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Prediction: [0.08248413]\n",
            "Actual: 0\n",
            "[0.335410475730896, 0.8704800009727478]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"model.h5\")\n",
        "\n",
        "review_bad = \"This is the worst movie I have ever seen Death would have been sweeter than watching this awful awful awful movie\"\n",
        "review_good = \"holy shit this movie was epic I could watch this movie every day and still not watch it enough unbelievable screenplay and acting preformances all around\"\n"
      ],
      "metadata": {
        "id": "qBJ8ORcA2fzc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
